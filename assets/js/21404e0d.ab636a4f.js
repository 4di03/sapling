"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9012],{3905:(e,n,t)=>{t.r(n),t.d(n,{MDXContext:()=>l,MDXProvider:()=>u,mdx:()=>g,useMDXComponents:()=>m,withMDXComponents:()=>p});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(){return i=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e},i.apply(this,arguments)}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function d(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),p=function(e){return function(n){var t=m(n.components);return a.createElement(e,i({},n,{components:t}))}},m=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):d(d({},n),e)),t},u=function(e){var n=m(e.components);return a.createElement(l.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},h=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),p=m(t),u=r,h=p["".concat(o,".").concat(u)]||p[u]||c[u]||i;return t?a.createElement(h,d(d({ref:n},l),{},{components:t})):a.createElement(h,d({ref:n},l))}));function g(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=h;var d={};for(var s in n)hasOwnProperty.call(n,s)&&(d[s]=n[s]);d.originalType=e,d.mdxType="string"==typeof e?e:r,o[1]=d;for(var l=2;l<i;l++)o[l]=t[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}h.displayName="MDXCreateElement"},9623:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>d,toc:()=>l});var a=t(83117),r=(t(67294),t(3905));const i={},o="IndexedLog",d={unversionedId:"dev/internals/indexedlog",id:"dev/internals/indexedlog",title:"IndexedLog",description:"IndexedLog is the main on-disk storage format used by various components in",source:"@site/docs/dev/internals/indexedlog.md",sourceDirName:"dev/internals",slug:"/dev/internals/indexedlog",permalink:"/docs/dev/internals/indexedlog",draft:!1,editUrl:"https://github.com/facebookexperimental/eden/tree/main/website/docs/dev/internals/indexedlog.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"DrawDag",permalink:"/docs/dev/internals/drawdag"},next:{title:"Internal differences from Mercurial",permalink:"/docs/dev/internals/internal-difference-hg"}},s={},l=[{value:"Background",id:"background",level:2},{value:"Log",id:"log",level:2},{value:"Index",id:"index",level:2},{value:"Standalone index",id:"standalone-index",level:2},{value:"Concurrent writes",id:"concurrent-writes",level:2},{value:"Data integrity",id:"data-integrity",level:2},{value:"RotateLog",id:"rotatelog",level:2}],p={toc:l};function m(e){let{components:n,...t}=e;return(0,r.mdx)("wrapper",(0,a.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,r.mdx)("h1",{id:"indexedlog"},"IndexedLog"),(0,r.mdx)("p",null,"IndexedLog is the main on-disk storage format used by various components in\nSapling."),(0,r.mdx)("h2",{id:"background"},"Background"),(0,r.mdx)("p",null,"Historically, ",(0,r.mdx)("a",{parentName:"p",href:"https://www.mercurial-scm.org/wiki/Revlog"},"revlog")," was the main\nstorage format, but it has a few limitations:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Revisions have to be topologically ordered.")," When revisions are fetched on\ndemand, if a later revision was fetched first, then it's impossible to append\nan older (ancestor) revision."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Lookup by hash can trigger a linear scan.")," The slowness this causes\nbecomes noticeable when there are lots of revisions. It can be worked around\nby building separate indexes."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Not general purpose enough to fit various use-cases.")," For example, the\n",(0,r.mdx)("a",{parentName:"li",href:"https://www.mercurial-scm.org/wiki/CEDObsstoreFormat"},"obsstore")," would\nrequire looking up a record by various indexes: predecessors or successors,\nand one record can have multiple predecessors or successors. In Revlog, one\nrecord can only have one SHA1 hash as its key.")),(0,r.mdx)("p",null,(0,r.mdx)("a",{parentName:"p",href:"https://git-scm.com"},"Git"),"'s format (loose and pack files) does not have the\ntopological order limitation, and lookup by hash is ideally O(log N), unless\nthere are too many pack files. But it requires periodical ",(0,r.mdx)("inlineCode",{parentName:"p"},"repack")," to maintain\nperformance, and does not support the multi-index use-case."),(0,r.mdx)("p",null,(0,r.mdx)("a",{parentName:"p",href:"https://www.sqlite.org/"},"SQLite"),' is a powerful library that satisfies the\nmulti-index use-cases, and can maintain time complexity without "repack".\nHowever, the main problem is that historically we use the "append-only"\nstrategy to achieve lock-free reads, but SQLite requires locking for both read\nand write.'),(0,r.mdx)("p",null,"IndexedLog is built to achieve the following desired properties:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"O(log N) lookup")," and does not require ",(0,r.mdx)("inlineCode",{parentName:"li"},"repack")," to maintain performance."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Insertion by hash")," without topological order limitation."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Lock-free reading"),' which primarily means "append-only larger files" and\n"atomic-replace small files" using the filesystem APIs we have today.\nTransactional filesystem or chunk-level copy-on-write could make a\ndifference but they are generally not available.'),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"General purpose")," with multi-index and multi-key per entry support.")),(0,r.mdx)("p",null,"In addition, we think the property below is nice to have:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("strong",{parentName:"li"},"Data integrity.")," In case of hard reboots, or accidental ",(0,r.mdx)("inlineCode",{parentName:"li"},"sed -i")," on the\nrepository data, we want to understand exactly what parts of the data are\ncorrupted, and have a way to recover.")),(0,r.mdx)("h2",{id:"log"},"Log"),(0,r.mdx)("p",null,"An IndexedLog consists of a Log and multiple surrounding Indexes. The Log is\nthe single source of truth for the data. The indexes are derived purely from\nthe Log and index functions. Corrupted indexes can be deleted and rebuilt as\nlong as the Log is fine."),(0,r.mdx)("p",null,"A Log stores entries in insertion order. An entry consists of a slice of\nbytes. ",(0,r.mdx)("inlineCode",{parentName:"p"},"Log")," is interface-wise similar to ",(0,r.mdx)("inlineCode",{parentName:"p"},"LinkedList<Vec<u8>>"),", but only\naccepts ",(0,r.mdx)("inlineCode",{parentName:"p"},"push_back"),", not ",(0,r.mdx)("inlineCode",{parentName:"p"},"push_front"),"."),(0,r.mdx)("p",null,"A Log supports the following operations:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"Iterate through all entries in insertion order."),(0,r.mdx)("li",{parentName:"ul"},"Append a new entry to the end.")),(0,r.mdx)("p",null,"A Log does not support:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"Read an entry by its offset (random access)."),(0,r.mdx)("li",{parentName:"ul"},"Remove an entry.")),(0,r.mdx)("p",null,"Unlike a relational or document database, Log itself does not define the\nmeaning of the bytes in an entry. The meaning is up to the application to\ndecide."),(0,r.mdx)("h2",{id:"index"},"Index"),(0,r.mdx)("p",null,"A Log can have multiple indexes. An index has a name, and a pure function that\ntakes the byte slice of an entry, and outputs a list of ",(0,r.mdx)("inlineCode",{parentName:"p"},"IndexOutput"),"s."),(0,r.mdx)("p",null,"Each ",(0,r.mdx)("inlineCode",{parentName:"p"},"IndexOutput")," is an enum that instructs IndexedLog to do one of the\nfollowing:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"Insert a key (in bytes) that points to the current entry."),(0,r.mdx)("li",{parentName:"ul"},"Remove a key or remove keys with a given prefix.")),(0,r.mdx)("p",null,"Unlike databases, the index function is in native Rust and not a separate\nlanguage like SQL or JSON. Note that it is impossible to serialize a compiled\nRust function to disk, so applications need to provide the exact same index\nfunctions when loading an IndexedLog from disk."),(0,r.mdx)("p",null,"If you change an index function, you need to also change the index name to\nprevent the IndexedLog from picking up the wrong index data."),(0,r.mdx)("h2",{id:"standalone-index"},"Standalone index"),(0,r.mdx)("p",null,"The Index can be used independently from Log. Its interface is similar\nto ",(0,r.mdx)("inlineCode",{parentName:"p"},"BTreeMap<Vec<u8>, LinkedList<u64>>"),", but uses the filesystem instead of\nmemory for the main storage."),(0,r.mdx)("p",null,"An Index supports:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"Insert (key, value). The value is inserted at the front of the existing\nlinked list. Alternatively, the existing linked list can be dropped."),(0,r.mdx)("li",{parentName:"ul"},"Lookup keys by a range."),(0,r.mdx)("li",{parentName:"ul"},"Delete keys in a range.")),(0,r.mdx)("p",null,"Internally, the key portion of the index is a\n",(0,r.mdx)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Radix_tree"},"radix tree")," where a node has 16\nchildren (4 bits). This is used to support hex prefix lookup. The value portion\nis a singly-linked list which supports ",(0,r.mdx)("inlineCode",{parentName:"p"},"push_front"),", but not ",(0,r.mdx)("inlineCode",{parentName:"p"},"push_back"),"."),(0,r.mdx)("p",null,"The on-disk format uses ",(0,r.mdx)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Persistent_data_structure#Trees"},"persistent data structure"),"\nto achieve lock-free reading. The main index is append-only. The pointer to the\nroot tree node is a small piece of data tracked separately using\natomic-replace."),(0,r.mdx)("p",null,"When used together with a Log, the ",(0,r.mdx)("inlineCode",{parentName:"p"},"u64")," part of ",(0,r.mdx)("inlineCode",{parentName:"p"},"LinkedList<u64>")," is used as\nfile offsets. The offsets are not exposed in public APIs of Log to avoid\nmisuse. The Log allows the on-disk indexes to lag for some entries because\nupdating the index for 1 entry takes O(log N) space, inefficient for frequent\nsmall writes. The lagging portion of index will be built on demand in memory."),(0,r.mdx)("h2",{id:"concurrent-writes"},"Concurrent writes"),(0,r.mdx)("p",null,"When an IndexedLog (or a standalone Index) gets loaded from disk, it is like\ntaking a snapshot. Changes on disk afterwards won't affect the already loaded\nIndexedLog (as long as all writes to the files go through IndexedLog APIs)."),(0,r.mdx)("p",null,"Writes are buffered in memory, lock-free. They are invisible to other processes\nor other already loaded IndexedLogs."),(0,r.mdx)("p",null,"A ",(0,r.mdx)("inlineCode",{parentName:"p"},"sync")," operation is needed to write data to disk, or load changed data from\ndisk. The ",(0,r.mdx)("inlineCode",{parentName:"p"},"sync")," will take a filesystem lock to prevent other writers, pick up\nthe latest filesystem state if anything has changed on disk, write the updated\nlog and indexes to disk, then release the lock."),(0,r.mdx)("p",null,"If 2 processes (or 2 IndexedLogs in one process) are ",(0,r.mdx)("inlineCode",{parentName:"p"},"sync()"),"-ing to the same\nIndexedLog on disk concurrently, both their pending changes will be written.\nThe order of the written data is unspecified, depends on which one obtains the\nfilesystem lock first."),(0,r.mdx)("h2",{id:"data-integrity"},"Data integrity"),(0,r.mdx)("p",null,"Both Log and Index use ",(0,r.mdx)("a",{parentName:"p",href:"http://www.xxhash.com/"},"xxhash")," for data integrity.\nLog writes a XXH32 or XXH64 checksum per entry depending on the size of the\nentry.  Index internally maintains checksum entries per 1MB data. All data\nreading triggers integrity checks. Errors will be reported to the application."),(0,r.mdx)("p",null,'IndexedLog supports a "repair" operation which truncates the Log to entries\nthat pass the integrity check and then rebuilds the corrupted or outdated\nindexes.'),(0,r.mdx)("h2",{id:"rotatelog"},"RotateLog"),(0,r.mdx)("p",null,"RotateLog applies the\n",(0,r.mdx)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Log_rotation"},"log rotation")," idea to IndexedLog.\nRotateLog maintains a list of Logs. When a Log exceeds certain size limit,\nRotateLog creates a new Log and optionally delete the oldest ones."),(0,r.mdx)("p",null,"RotateLog is intended to be used for client-side caching, where the client\nwants space usage to be bounded, and the data can be re-fetched from the\nserver."))}m.isMDXComponent=!0}}]);